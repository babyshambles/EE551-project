<<<<<<< HEAD

=======
Self-Driving Lane Lines Detection 
=======
Introduction
-------
Self-driving, as the same meaning of autonomous car or driverless car, is a vehicle that is capable of sensing its environment 
and moving with little or no human input. It does a significant convenience to human's real life. One of self-driving sensor is
camera, driverless car uses a front-facing camera to collect the environment information and produces real-time video to help the car sensing 
the situation. So detecting the lane lines is a very important issue, this project is to create a improved lane finding 
algorithm using computer vision techniques. The core of this project is to identify the lane boundry in the camera video. This 
peoject is mainly about these below sections.<br>
This project is mainly to write a python algerithm to identify the lane boundary from a front facing camera.

## Section 1: Camera Calibration
When a camera captures 3D objects in the real world it transforms them into 2D images, this transform is not exact and modifies
the objects shape and size. In order to correct the distortion of we need to analyze images generated by the camera, calitrate
it and use the distortion parameters to correct other images taken with it.

### Distortion Measurement
In this project, chessboard pattern is used to measure the distortion of a camera. We use OpenCV to do this measurement. 
OpenCV provides several functions such as findChessboardCorners(), drawChessboardCorners(), to find and draw corners on an
chessboard pattern image. The main algerithm is, we assuming the chessboard pattern is fixed on the (x,y) plane at z=0 while the 
real world coordinate is (x,y,z). ''Object points'' represents the corners and on the (x,y) plane is the same for each calibration
image. ''imgpoints'' is append with (x,y) pixel position of each corners in the image plane. And an example of corner detection 
is shown as below:
![Image of a chessboard pattern with marked corners](https://github.com/babyshambles/EE551-project/blob/master/Read_image/Corners_found.png)

### Camera Matrix and Distortion Coefficients
This part we use the function cv2.calibrateCamera() to get the camera matrix and distortion coefficients.

### Image Undistortion
In this part we define a function named undistortion() to correct the distortion of a certain image. This defined function 
is mainly using the cv2.undistort() function and camera matrix and distortion coefficients calculated in the last part. And a sample
results is shown as below:
![Undistorted sample](https://github.com/babyshambles/EE551-project/blob/master/Read_image/Undistorted.jpg)

## Section 2: Color and Gradient Threshold
Color and gradient thresholds are used to identify the lane markings. This part is mainly about running the image through an 
almost empirical combination of methods that process color channels and gradients in order to create a binary image that just 
contains the lane pixels

### Binary Image
As we know, in the real driving road, shadows and glares are quite challenge for lane detection, so here we use a adaptive thresholds
which is described below arose.
A red channel image is used to find white line, and we make a linear combination between the red and saturation channel
(where sat_hls returns a given color image) to detect the yellow line. And a example for yellow line detection is shown as below:
![Grayscale image](https://github.com/babyshambles/EE551-project/blob/master/Read_image/sat_hls_img.jpg)

### Birds' Eye Transformation
As we know, parallel lines appear to converge on an image taken from the front facing camera of the car due to the perspective.
Birds' eye transformation is applied to keep parallel line parallel. We shrink the bottom edge of an image and produce the same
scale of the road to the top of the image. This transformation preserves all avaliable pixels from the original image on the top
of the image where we have lower resolution.
Here we use cv2.getPerspectiveTransform()function to implement the Birds' eye transformation. We also define a function transform()
to get the warped image from the original. Of course this test image is undistorted before the transformation. And a sample images
showing original, undistorted and warped image are shown as below:
![Warped image](https://github.com/babyshambles/EE551-project/blob/master/Read_image/warped_img.jpg)
As we can see, this warped image shows that the converged lines become parallel roughly and this warped image is used for following processing

## Section 3: The Lane Class
Once the pixels corresponding to the lane lines are dentified in section2, curve fitting can be done to detrmine the driable 
region, in order to facilitate book-keeping, a python class definiton for the lane making lines was used.
In this part, image should be analyzed with adaptive virtual sensors which are a string of pixels. These sensors are used to
find a line in an expected area. When the line point's value minus the mean pixel of the certain sensor is larger than the threshold, the line point is considered found.
The threshold in every sensor should be selected based on mean value of pixels in the sensor. And how to find a certain perfect threshold in sensor is very challenging.
Then we applied the set of points found by sensor to a polynomial fit, and the best order of the polynomial should be chosen for every point set  individually.

### Radius of Curvature
One important part of line finding is to estimate the radius of the road curvature. The radius of the curvature is given in meters assuming the curve of the road follows a circle. The radius of lanes is calculated by the polynomial lane lines approximation by the r_cur function by a formula(referenced by a [website](http://www.intmath.com/applications-differentiation/8-radius-curvature.php)). If the radius is bigger than a Max_Radius(here is 10000) then return this Max_Radius value because such big curvature can be considered as a straight line.

### Equidistant
When the case only one line is well determined, we should make another line with equidistant because the line is parallel. While in order to make line fitting robust and stable, the equidistant polinomial should have not higher than 3rd order polynomial. So we creat a list of equidistant points for the given polynomial, these points are on the straight lines and perpendicular to the given polynomial at selected points on a deseired distance. And then use the same order polynomial to fit them. In the code, the np.polyfit is used to fit. And the equidistant plot is shown as below:
![Plot of an Equidistant](https://github.com/babyshambles/EE551-project/blob/master/Read_image/equidistant.jpg)

### Order of the polynomial
One of the key ideas is using the minimal order of polynomial functions for lines fitting. And in the code, the best_pol_ord chooses such a order. See the code chunk in retail

## Section 4: Line finding
In this part the we use the draw_line function(see in the code) to make the found line visualization.If we implement it on an image, it will draw a lane line, and in case of a video, it will also prints the radius of the road curvature and the offset from the lane center.
Here we use the test images in the test_images file to do the test and the results are shown as below:

![Read_image/original_jpg](https://github.com/babyshambles/EE551-project/blob/master/Read_image/original_img.jpg)
![Read_image/warped_jpg](https://github.com/babyshambles/EE551-project/blob/master/Read_image/warped.jpg)
![Read_image/lineDrawed_jpg](https://github.com/babyshambles/EE551-project/blob/master/Read_image/lineDrawed.jpg)



## Section 5: Visualization
This part will make a visualization of the intermediate video at each section described above. The drivable lane region is superimposed on the original video frames.
In this part the code chunk get_lane_video performs these actions, in this algorithm line considered as detected only if there are more than Min_pointspoints found and if it is failed to find the line for more than Max_frame video frame, it starts from scratch. And this algerithm also skip the certain narrow and wide lanes. If it dont know the position of the lane for more than Max_frame frames, it will also draw nothing. If only one line of the lane is detected, then the algorithm will use the equidistant function to draw another line.

<<<<<<< HEAD
### Author: Yufei Wang
>>>>>>> 3fcec88390ec62a9be939df004e100b4be808e15
=======
Author: Yufei Wang

Referenced by [CarND-Advanced-Lane-Lines](https://github.com/svanimisetti/CarND-Advanced-Lane-Lines)
>>>>>>> 49013f84ae4f9606e7f14de82c5706c8183639ef
